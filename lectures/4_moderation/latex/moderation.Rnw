%%% Title:    Regression in R 5: Moderation
%%% Author:   Kyle M. Lang
%%% Created:  2017-09-12
%%% Modified: 2022-01-30

\documentclass[10pt]{beamer}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{caption}

\title{Moderation}
\subtitle{Utrecht University Winter School: Regression in R}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{2022-02-02}

% Don't use any labeling for table captions
\captionsetup{labelformat = empty}

%------------------------------------------------------------------------------%

\begin{document}

<<setup, include=FALSE, cache = FALSE>>=
set.seed(235711)

library(knitr)
library(ggplot2)
library(MASS)
library(DAAG)
library(xtable)
library(MLmetrics)

source("../../../code/supportFunctions.R")

dataDir <- "../../../data/"

options(width = 60)
opts_chunk$set(size = "footnotesize",
               fig.align = "center",
               fig.path = "figure/moderation-",
               message = FALSE,
               warning = FALSE,
               comment = "")
knit_theme$set('edit-kwrite')
@

%------------------------------------------------------------------------------%

\begin{frame}[t, plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents  
\end{frame}

%------------------------------------------------------------------------------%

\section{Moderation}

%------------------------------------------------------------------------------%

\begin{frame}{Moderation}

  So far we've been discussing \emph{additive models}.
  \vb
  \begin{itemize}
  \item Additive models allow us to examine the partial effects of several
    predictors on some outcome.
    \vc
    \begin{itemize}
    \item The effect of one predictor does not change based on the values of 
      other predictors.
    \end{itemize}
  \end{itemize}
  \va
  Now, we'll discuss \emph{moderation}.
  \vb
  \begin{itemize}
  \item Moderation allows us to ask \emph{when} one variable, $X$, affects
    another variable, $Y$.
    \vc
    \begin{itemize}
    \item We're considering the conditional effects of $X$ on $Y$ given certain 
      levels of a third variable $Z$.
    \end{itemize}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Equations}

  In additive MLR, we might have the following equation:
  \begin{align*}
    Y = \beta_0 + \beta_1X + \beta_2Z + \varepsilon
  \end{align*}
  This additive equation assumes that $X$ and $Z$ are independent
  predictors of $Y$.\\
  \va
  When $X$ and $Z$ are independent predictors, the following are true:
  \vb
  \begin{itemize}
  \item $X$ and $Z$ \emph{can} be correlated.
    \vb
  \item $\beta_1$ and $\beta_2$ are \emph{partial} regression
    coefficients.
    \vb
  \item \red{The effect of $X$ on $Y$ is the same at \textbf{all levels} of
    $Z$, and the effect of $Z$ on $Y$ is the same at \textbf{all
      levels} of $X$.}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Additive Regression}
  
  The effect of $X$ on $Y$ is the same at \textbf{all levels} of $Z$.
  
  \begin{columns}
    \begin{column}{0.45\textwidth}
      \includegraphics[width = 1.1\textwidth]{figures/3d_data_plot}
    \end{column}
    
    \begin{column}{0.1\textwidth}
      \begin{center}\Huge{$\rightarrow$}\end{center}
    \end{column}
    
    \begin{column}{0.45\textwidth}
      \includegraphics[width = 1.1\textwidth]{figures/response_surface_plot0}
    \end{column}
  \end{columns}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Moderated Regression}
  
  The effect of $X$ on $Y$ varies \textbf{as a function} of $Z$.
  
  \begin{columns}
    \begin{column}{0.45\textwidth}
      \includegraphics[width = 1.1\textwidth]{figures/3d_data_plot}
    \end{column}
    
    \begin{column}{0.1\textwidth}
      \begin{center}\Huge{$\rightarrow$}\end{center}
    \end{column}
    
    \begin{column}{0.45\textwidth}
      \includegraphics[width = 1.1\textwidth]{figures/response_surface_plot}
    \end{column}
  \end{columns}
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Equations}
  
  The following derivation is adapted from \citet{hayes:2018}.
  \vb
  \begin{itemize}
  \item When testing moderation, we hypothesize that the effect of $X$ on $Y$ 
    varies as a function of $Z$.  
    \vb
  \item We can represent this concept with the following equation:
    \begin{align}
      Y = \beta_0 + f(Z)X + \beta_2Z + \varepsilon \label{fEq}
    \end{align}
    \vx{-8}
    \pause
  \item If we assume that $Z$ linearly (and deterministically) affects the 
    relationship between $X$ and $Y$, then we can take:
    \begin{align}
      f(Z) = \beta_1 + \beta_3Z \label{ssEq}
    \end{align}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Equations}
  
  \begin{itemize}
  \item Substituting Equation \ref{ssEq} into Equation \ref{fEq} leads to:
    \begin{align*}
      Y = \beta_0 + (\beta_1 + \beta_3Z)X + \beta_2Z + \varepsilon
    \end{align*}
    \pause
  \item Which, after distributing $X$ and reordering terms, becomes:
    \begin{align*}
      Y = \beta_0 + \beta_1X + \beta_2Z + \beta_3XZ + \varepsilon
    \end{align*}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\subsection{Testing Moderation}

%------------------------------------------------------------------------------%

\begin{frame}{Testing Moderation}
  Now, we have an estimable regression model that quantifies the linear 
  moderation we hypothesized.
  \vb
  \begin{center}\ovalbox{$Y = \beta_0 + \beta_1X + \beta_2Z + \beta_3XZ + 
      \varepsilon$}\end{center}
  \vc
  \begin{itemize}
  \item To test for significant moderation, we simply need to test the 
    significance of the interaction term, $XZ$.
    \begin{itemize}
    \item Check if $\hat{\beta}_3$ is significantly different from zero.
    \end{itemize}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Interpretation}
  
  Given the following equation:
  \begin{align*}
    Y = \hat{\beta}_0 + \hat{\beta}_1X + \hat{\beta}_2Z + \hat{\beta}_3XZ + 
    \hat{\varepsilon}
  \end{align*}
  \vx{-16}
  \begin{itemize}
  \item $\hat{\beta}_3$ quantifies the effect of $Z$ on the focal effect (the $X 
    \rightarrow Y$ effect).
    \vc
    \begin{itemize}
    \item For a unit change in $Z$, $\hat{\beta}_3$ is the expected change in
      the effect of $X$ on $Y$.
    \end{itemize}
    \vb
  \item $\hat{\beta}_1$ and $\hat{\beta}_2$ are \emph{conditional effects}.
    \vc
    \begin{itemize}
      \item Interpreted where the other predictor is zero.
        \vc
      \item For a unit change in $X$, $\hat{\beta}_1$ is the expected change in
        $Y$, when $Z = 0$.
        \vc
      \item For a unit change in $Z$, $\hat{\beta}_2$ is the expected change in
        $Y$, when $X = 0$.
    \end{itemize}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%
  
\begin{frame}{Example}
  
  Still looking at the \emph{diabetes} dataset.
  \va 
  \begin{itemize}
  \item We suspect that patients' BMIs are predictive of their average blood 
    pressure. 
    \va 
  \item We further suspect that this effect may be differentially expressed 
    depending on the patients' LDL levels.
  \end{itemize}
  
\end{frame}

\watermarkoff%-----------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<echo = FALSE>>=
dDat <- readRDS(paste0(dataDir, "diabetes.rds"))
@ 

<<>>=
## Focal Effect:
out0 <- lm(bp ~ bmi, data = dDat)
partSummary(out0, -c(1, 2))
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
## Additive Model:
out1 <- lm(bp ~ bmi + ldl, data = dDat)
partSummary(out1, -c(1, 2))
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
## Moderated Model:
out2 <- lm(bp ~ bmi * ldl, data = dDat)
partSummary(out2, -c(1, 2))
@

\end{frame}

%------------------------------------------------------------------------------%

\section{Probing Interactions}

%------------------------------------------------------------------------------%

\begin{frame}{Visualizing the Interaction}

  \begin{columns}
    \begin{column}{0.5\textwidth}
      We can get a better idea of the patterns of moderation by plotting the 
      focal effect at conditional values of the moderator.
    \end{column}
    
    \begin{column}{0.5\textwidth}
      
<<echo = FALSE>>=
m1 <- mean(dDat$ldl)
s1 <- sd(dDat$ldl)

dDat$ldlLo  <- dDat$ldl - (m1 - s1)
dDat$ldlMid <- dDat$ldl - m1
dDat$ldlHi  <- dDat$ldl - (m1 + s1)

outLo  <- lm(bp ~ bmi*ldlLo, data = dDat)
outMid <- lm(bp ~ bmi*ldlMid, data = dDat)
outHi  <- lm(bp ~ bmi*ldlHi, data = dDat)

b0Lo <- coef(outLo)[1]
b1Lo <- coef(outLo)["bmi"]

b0Mid <- coef(outMid)[1]
b1Mid <- coef(outMid)["bmi"]

b0Hi <- coef(outHi)[1]
b1Hi <- coef(outHi)["bmi"]

x    <- seq(min(dDat$bmi), max(dDat$bmi), 0.1)
dat1 <- data.frame(x    = x,
                   yLo  = b0Lo + b1Lo * x,
                   yMid = b0Mid + b1Mid * x,
                   yHi  = b0Hi + b1Hi * x)

p1 <- ggplot(data = dDat, aes(x = bmi, y = bp)) +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16))
p2 <- p1 + geom_point(colour = "gray") +
    geom_line(mapping = aes(x = x, y = yLo, colour = "Mean LDL - 1 SD"),
              data    = dat1,
              size    = 1.5) +
    geom_line(mapping = aes(x = x, y = yMid, colour = "Mean LDL"),
              data    = dat1,
              size    = 1.5) +
    geom_line(mapping = aes(x = x, y = yHi, colour = "Mean LDL + 1 SD"),
              data    = dat1,
              size    = 1.5) +
    xlab("BMI") +
    ylab("BP")

p2 + scale_colour_manual(name = "", values = c("Mean LDL" = "black",
                                               "Mean LDL - 1 SD" = "red",
                                               "Mean LDL + 1 SD" = "blue")
                         ) +
    theme(legend.justification = c(1, 0), legend.position = c(0.975, 0.025))
@ 

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Probing the Interaction}

  A significant estimate of $\beta_3$ tells us that the effect of $X$ on $Y$ 
  depends on the level of $Z$, but nothing more.
  \vb
  \begin{itemize}
  \item The plot on the previous slide gives a descriptive illustration of the 
    pattern, but does not support statistical inference.
    \vc
    \begin{itemize}
    \item The three conditional effects we plotted look different, but we cannot 
      say much about how they differ with only the plot and $\hat{\beta}_3$.
    \end{itemize}
    \vb
  \item This is the purpose of \emph{probing} the interaction.
    \vc
    \begin{itemize}
    \item Try to isolate areas of $Z$'s distribution in which $X \rightarrow Y$
      effect is significant and areas where it is not.
    \end{itemize}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Probing the Interaction}

  The most popular method of probing interactions is to do a so-called 
  \emph{simple slopes} analysis.
  \vc
  \begin{itemize}
  \item Pick-a-point approach
    \vc
  \item Spotlight analysis
  \end{itemize}
  \vb
  In simple slopes analysis, we test if the slopes of the conditional effects 
  plotted above are significantly different from zero.
  \vc
  \begin{itemize}
  \item To do so, we test the significance of \emph{simple slopes}.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Simple Slopes}

  Recall the derivation of our moderated equation:
  \begin{align*}
    Y = \beta_0 + \beta_1X + \beta_2Z + \beta_3XZ + \varepsilon
  \end{align*}
  We can reverse the process by factoring out $X$ and reordering terms:
  \begin{align*}
    Y = \beta_0 + (\beta_1 + \beta_3Z)X + \beta_2Z + \varepsilon
  \end{align*}
  Where $f(Z) = \beta_1 + \beta_3Z$ is the linear function that shows how the 
  relationship between $X$ and $Y$ changes as a function of $Z$.\\
  \vc
  \begin{center}
  \ovalbox{$f(Z)$ is the \emph{simple slope}.}
  \end{center}
  \begin{itemize}
  \item By plugging different values of $Z$ into $f(Z)$, we get the value of the 
    conditional effect of $X$ on $Y$ at the chosen level of $Z$.
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Significance Testing of Simple Slopes}

  The values of $Z$ used to define the simple slopes are arbitrary.
  \vc
  \begin{itemize}
  \item The most common choice is: $\left\{ (\bar{Z} - SD_Z), \bar{Z},
    (\bar{Z} + SD_Z) \right\}$
    \vc
  \item You could also use interesting percentiles of $Z$'s distribution.
  \end{itemize}
  \vb
  The standard error of a simple slope is given by:
  \begin{align*}
    SE_{f(Z)} = \sqrt{SE_{\beta_1}^2 + 2Z \cdot \text{COV}(\beta_1, \beta_3) + 
      Z^2 SE_{\beta_3}^2}
  \end{align*}
  So, you can test the significance of a simple slope by constructing a Wald 
  statistic or confidence interval using $\hat{f}(Z)$ and $SE_{f(Z)}$:
  \begin{align*}
    t = \frac{\hat{f}(Z)}{SE_{f(Z)}},~~
    CI = \hat{f}(Z) \pm t_{crit} \times SE_{f(Z)}
  \end{align*}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Interaction Probing}
  
  When probed the interaction with simple slopes analysis:
  \vb
  \begin{enumerate}
    \item Choose interesting values of the moderator, $Z$. \label{chooseZ}
      \vb
    \item Check the significance of the focal effect, $X \rightarrow Y$, at the 
      $Z$ values chosen in Step \ref{chooseZ}. \label{testSS}
      \vb
    \item Use the results from Step \ref{testSS} to get an idea of where in 
      $Z$'s distribution the focal effect is or is not significant.
  \end{enumerate}
  \va
  \pause
  We saw manual calculations for the the quantities needed, but there is a 
  simpler way:
  \vc
  \begin{itemize}
    \item \textsc{Centering}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Centering}
  
  Centering shifts the scale of a variable up or down by subtracting a constant 
  (e.g., the variable's mean) from each of its observations.
  \vc
  \begin{itemize}
  \item The most familiar form of center is \emph{mean centering}.
    \vc
  \item We can center on any value.
    \vc
    \begin{itemize}
    \item When probing interactions, we can center $Z$ on the interesting values
      we choose to define the simple slopes.
      \vc
    \item Due to the interpretation of conditional effects, running the model 
      with $Z$ centered on a specific value automatically provides a test of the 
      simple slope for that value of $Z$.
    \end{itemize}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Probing via Centering}
  
  Say we want to do a simple slopes analysis to test the conditional effect of 
  $X$ on $Y$ at three levels of $Z = \{Z_1, Z_2, Z_3\}$.
  \vb
  \begin{itemize}
  \item All we need to do is fit the following three models:
    \begin{align*}
      Y &= \beta_0 + \beta_1X + \beta_2(Z - Z_1) + \beta_3 X(Z - Z_1) + 
      \varepsilon\\[10pt]
      Y &= \beta_0 + \beta_1X + \beta_2(Z - Z_2) + \beta_3 X(Z - Z_2) + 
      \varepsilon\\[10pt]
      Y &= \beta_0 + \beta_1X + \beta_2(Z - Z_3) + \beta_3 X(Z - Z_3) + 
      \varepsilon
    \end{align*}
    \pause
    \vx{-12}
  \item The default output for $\hat{\beta}_1$ provides tests of the simple 
    slopes.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  Create transformed predictors by centering on critical values of the 
  moderator, $Z_{LDL}$.
<<>>=
zMean     <- mean(dDat$ldl)
zSD       <- sd(dDat$ldl)
dDat$zCen <- dDat$ldl - zMean 
dDat$zHi  <- dDat$ldl - (zMean + zSD)
dDat$zLo  <- dDat$ldl - (zMean - zSD)
@ 

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  Test the simple slope of $X_{BMI} \rightarrow Y_{BP}$ at 1 $SD$ below the mean 
  of $Z_{LDL}$.
<<>>=
out2.1 <- lm(bp ~ bmi*zLo, data = dDat)
partSummary(out2.1, -c(1, 2))
@
The estimated slope for \texttt{bmi}, $\hat{\beta}_1 = 
\Sexpr{round(coef(out2.1)["bmi"], 3)}$, is the simple slope.
 
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  Test the simple slope of $X_{BMI} \rightarrow Y_{BP}$ at the mean of $Z_{LDL}$.
<<>>=
out2.2 <- lm(bp ~ bmi*zCen, data = dDat)
partSummary(out2.2, -c(1, 2))
@
The estimated slope for \texttt{bmi}, $\hat{\beta}_1 = 
\Sexpr{round(coef(out2.2)["bmi"], 3)}$, is the simple slope.
 
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
  
  Test the simple slope of $X_{BMI} \rightarrow Y_{BP}$ at 1 $SD$ above the mean 
  of $Z_{LDL}$.
<<>>=
out2.3 <- lm(bp ~ bmi*zHi, data = dDat)
partSummary(out2.3, -c(1, 2))
@
The estimated slope for \texttt{bmi}, $\hat{\beta}_1 = 
\Sexpr{round(coef(out2.3)["bmi"], 3)}$, is the simple slope.
 
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Compare Approaches}
  
  The manual and the centering approaches give identical answers, barring 
  rounding errors: 
  \vb
<<echo = FALSE, results = "asis">>=
## Specify function to compute simple slopes:
getSS <- function(z, lmOut) {
    tmp <- coef(lmOut)
    tmp[2] + tmp[4]*z
}
##
## Specify function to compute SE for simple slopes:
getSE <- function(z, lmOut) {
    tmp <- vcov(lmOut)
    varB1 <- tmp[2, 2]
    varB3 <- tmp[4, 4]
    covB13 <- tmp[4, 2]

    sqrt(varB1 + 2 * z * covB13 + z^2 * varB3)
}

## Compute vector of simple slopes:
ssVec <- sapply(c(zMean - zSD, zMean, zMean + zSD),
                FUN   = getSS,
                lmOut = out2)
##
## Compute vector of SEs for simple slopes:
seVec <- sapply(c(zMean - zSD, zMean, zMean + zSD),
                FUN   = getSE,
                lmOut = out2)

ssVec2 <- c(coef(out2.1)["bmi"],
            coef(out2.2)["bmi"],
            coef(out2.3)["bmi"])

seVec2 <- c(sqrt(diag(vcov(out2.1)))["bmi"],
            sqrt(diag(vcov(out2.2)))["bmi"],
            sqrt(diag(vcov(out2.3)))["bmi"])

ssMat <- rbind(ssVec, ssVec2)
seMat <- rbind(seVec, seVec2)

colnames(ssMat) <- colnames(seMat) <- c("Z Low", "Z Center", "Z High")
rownames(ssMat) <- rownames(seMat) <- c("Manual", "Centering")

ssTab <- xtable(ssMat, 
                align   = "rccc",
                caption = "Simple Slopes",
                digits  = 6)
seTab <- xtable(seMat, 
                align   = "rccc",
                caption = "Standard Errors",
                digits  = 6)

print(ssTab, booktabs = TRUE)
@ 

\vx{-6}

<<echo = FALSE, results = "asis">>=
print(seTab, booktabs = TRUE)
@

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\section{Categorical Moderators}

%------------------------------------------------------------------------------%

\begin{frame}{Categorical Moderators}
  
  Categorical moderators encode \emph{group-specific} effects.
  \vb
  \begin{itemize}
  \item E.g., if we include \emph{sex} as a moderator, we are modeling separate
    focal effects for males and females.
  \end{itemize}
  \va 
  Given a set of codes representing our moderator, we specify the
  interactions as before:
  \begin{align*}
    Y_{total} &= \beta_0 + \beta_1 X_{inten} + \beta_2 Z_{male} + 
    \beta_3 X_{inten}Z_{male} + \varepsilon\\\\
    Y_{total} &= \beta_0 + \beta_1 X_{inten} + \beta_2 Z_{lo} + \beta_3 Z_{mid} + 
    \beta_4 Z_{hi}\\ 
    &+ \beta_5 X_{inten}Z_{lo} + \beta_6 X_{inten}Z_{mid} + \beta_7 X_{inten}Z_{hi} + 
    \varepsilon
  \end{align*}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}
  
<<>>=
## Load data:
socSup <- readRDS(paste0(dataDir, "social_support.rds"))

## Focal effect:
out3 <- lm(bdi ~ tanSat, data = socSup)
partSummary(out3, -c(1, 2))
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
## Estimate the interaction:
out4 <- lm(bdi ~ tanSat * sex, data = socSup)
partSummary(out4, -c(1, 2))
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  On the last slide, the estimated slope for \texttt{tanSat}, $\hat{\beta}_1 = 
  \Sexpr{round(coef(out4)["tanSat"], 3)}$, is the simple slope for females.
  \vc
  \begin{itemize}
  \item To estimate the simple slope for males, we simply change the reference 
    group of the \texttt{sex} factor and re-estimate the model.
  \end{itemize}
  
<<>>=
## Test the 'male' simple slope by changing reference group:
socSup$sex2 <- relevel(socSup$sex, ref = "male")

## Re-estimate the interaction:
out5 <- lm(bdi ~ tanSat * sex2, data = socSup)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
partSummary(out5, -c(1, 2))
@ 

The estimated slope for \texttt{tanSat}, $\hat{\beta}_1 = 
\Sexpr{round(coef(out5)["tanSat"], 3)}$, is now the simple slope for males.

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Visualizing Categorical Moderation}

  \begin{columns}
    \begin{column}{0.5\textwidth}
      {\scriptsize
        \vx{-12}
        \begin{align*}
          \hat{Y}_{BDI} &= \Sexpr{sprintf('%.2f', round(coef(out4)[1], 2))} 
            \Sexpr{sprintf('%.2f', round(coef(out4)[2], 2))} X_{tsat} + 
              \Sexpr{sprintf('%.2f', round(coef(out4)[3], 2))} Z_{male}\\ 
                &\Sexpr{sprintf('%.2f', round(coef(out4)[4], 2))} 
                  X_{tsat} Z_{male}
        \end{align*}
        \vx{-12}
      }
<<echo = FALSE, warning = FALSE>>=
out66 <- lm(BDI ~ tangiblesat + gender, data = socsupport)

p3 <- ggplot(data    = socsupport, 
             mapping = aes(x = tangiblesat, y = BDI, colour = gender)) +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16))

p4 <- p3 + geom_jitter(na.rm = TRUE) +
    scale_colour_manual(values = c("red", "blue"))

p4 + geom_abline(slope     = coef(out4)["tanSat"],
                 intercept = coef(out4)[1],
                 colour    = "red",
                 size      = 1.5) +
    geom_abline(slope     = coef(out5)["tanSat"],
                intercept = coef(out5)[1],
                colour    = "blue",
                size      = 1.5) + 
    ggtitle("Moderation by Gender") +
    xlab("Tangible Satisfaction") +
    theme(plot.title = element_text(hjust = 0.5, size = 20, face = 2))
@ 

\end{column}

\begin{column}{0.5\textwidth}
  {\scriptsize
    \begin{align*}
      \hat{Y}_{BDI} = \Sexpr{sprintf('%.2f', round(coef(out66)[1], 2))}  
      \Sexpr{sprintf('%.2f', round(coef(out66)[2], 2))} X_{tsat}  
      \Sexpr{sprintf('%.2f', round(coef(out66)[3], 2))} Z_{male}
    \end{align*}
    \vx{-6}
  }
<<echo = FALSE>>=
p4 + geom_abline(slope     = coef(out66)["tangiblesat"],
                 intercept = coef(out66)[1],
                 colour    = "red",
                 size      = 1.5) +
    geom_abline(slope     = coef(out66)["tangiblesat"],
                intercept = (coef(out66)[1] + coef(out66)["gendermale"]),
                colour    = "blue",
                size      = 1.5) +
    ggtitle("Additive Gender Effect") +
    xlab("Tangible Satisfaction") +
    theme(plot.title = element_text(hjust = 0.5, size = 20, face = 2))
@ 

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{References}

  \bibliographystyle{apacite}
  \bibliography{../../../bibtex/winter_school_refs.bib}

\end{frame}

\end{document}

